<div align="center">

# Neuro-SAM 
#### Foundation Models from Dendrite and Dendritic Spine Segmentation

[![python](https://img.shields.io/badge/-Python_3.10-blue?logo=python&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![pytorch](https://img.shields.io/badge/PyTorch_2.0+-ee4c2c?logo=pytorch&logoColor=white)](https://pytorch.org/get-started/locally/)
[![wandb](https://img.shields.io/badge/Weights_&_Biases-FFCC33?logo=WeightsAndBiases&logoColor=black)](https://wandb.ai/site)

This project demonstrates an interactive UI to segment dendrites and dendritic spines.
The model of choice is SAMv2 and the framework used is pytorch.

![A stack of neural dendrites and dendritic spines](./assets/merged_dendrites_spines.gif "Dendrites and Dendritic Spines")

</div>

### ğŸ“  Table of Contents

- [Neuro-SAM](#neuro-sam)
  - [ğŸ“‘ Table of Contents](#--table-of-contents)
  - [ğŸ§  Overview](#-overview)
  - [ğŸ“¦ Built With](#-built-with)
  - [ğŸ“‚ Repository Structure](#-repository-structure)
  - [ğŸš€ Installation](#-installation)
  - [ğŸ“Š Usage](#-usage)
  - [ğŸ›  Workflow](#-workflow)
  - [ğŸ§‘â€ğŸ’» Model Training](#-model-training)
  - [ğŸ“ Data Format](#-data-format)
  - [ğŸ“„ License](#-license)
  - [ğŸ“¬ Contact](#-contact)


### ğŸ§  Overview

Neuro-SAM provides an end-to-end pipeline for analyzing neural structures from 3D microscopy data, featuring:

- **Path Tracing**: Waypoint-based A* pathfinding
- **Dendrite Segmentation**: SAM2-based dendrite segmentation
- **Smart Spine Detection**: Multi-view analysis for spine detection
- **Spine Segmentation**: Individual spine segmentation using trained SAM2 model

### ğŸ“¦ Built With

[PyTorch](https://pytorch.org) - an open-source machine learning library for Python, widely used for deep learning applications.

[Segment Anything Model](https://segment-anything.com) - a foundation model used for segmentation built by Meta AI.

[Weights and Biases](https://wandb.ai/site) - a tool for tracking and visualizing machine learning experiments.

[Visual Studio Code](https://code.visualstudio.com/) - a code editor redefined and optimized for building applications.

[FAU High Performance Computing](https://doc.nhr.fau.de/) - a high-performance computing cluster at Friedrich-Alexander-UniversitÃ¤t Erlangen-NÃ¼rnberg.

### ğŸ“ Repository Structure

```
Neuro-SAM/
â”œâ”€â”€ Train-SAMv2/                    # SAM2 training infrastructure
â”‚   â”œâ”€â”€ sam2/                       # SAM2 model implementation
â”‚   â”œâ”€â”€ checkpoints/                # Model checkpoints
â”‚   â”œâ”€â”€ results/                    # Trained model outputs
â”‚   â”œâ”€â”€ utils/                      # Training utilities
â”‚   â”œâ”€â”€ train_dendrites.py         # Dendrite model training
â”‚   â””â”€â”€ train_spines.py            # Spine model training
â”œâ”€â”€ brightest_path_lib/             # Advanced pathfinding algorithms
â”‚   â”œâ”€â”€ algorithm/                  # A* and waypoint search implementations
â”‚   â”œâ”€â”€ cost/                       # Cost function definitions
â”‚   â”œâ”€â”€ heuristic/                  # Heuristic functions
â”‚   â”œâ”€â”€ visualization/              # Path visualization tools
â”‚   â””â”€â”€ ...
â”œâ”€â”€ napari_utils/                   # Napari plugin components
â”‚   â”œâ”€â”€ main_widget.py             # Main interface with anisotropic scaling
â”‚   â”œâ”€â”€ path_tracing_module.py     # Interactive path tracing
â”‚   â”œâ”€â”€ segmentation_module.py     # Dendrite segmentation interface
â”‚   â”œâ”€â”€ spine_detection_module.py  # Spine detection with smart tracking
â”‚   â”œâ”€â”€ spine_segmentation_module.py # Individual spine segmentation
â”‚   â””â”€â”€ visualization_module.py    # Path management and visualization
â””â”€â”€ neuro_sam_plugin.py            # Main plugin entry point
```

### ğŸš€ Installation

#### Prerequisites

- Python 3.10+
- CUDA-compatible GPU (recommended)
- Conda/Miniconda

#### Environment Setup

1. **Clone the repository:**
```bash
git clone https://github.com/nipunarora8/Neuro-SAM.git
cd Neuro-SAM
```

2. **Create conda environment:**
```bash
conda env create -f environment.yml
conda activate sam2
```

3. **Download SAM2 checkpoints:**
```bash
cd Train-SAMv2/checkpoints
bash download_ckpts.sh
```

### ğŸ“Š Usage

#### Quick Start

```python
from neuro_sam_plugin import run_neuro_sam

# Launch with default spacing (94nm x 94nm x 500nm)
viewer = run_neuro_sam(image_path="your_image.tif")

# Launch with custom voxel spacing
viewer = run_neuro_sam(
    image_path="your_image.tif",
    spacing_xyz=(100.0, 100.0, 300.0)  # X, Y, Z spacing in nm
)
```

#### Command Line Interface

```bash
# Basic usage
python neuro_sam_plugin.py --image_path /path/to/your/image.tif

# Custom spacing
python neuro_sam_plugin.py --image_path image.tif \
    --x-spacing 100.0 --y-spacing 100.0 --z-spacing 300.0

# Load benchmark dataset
python neuro_sam_plugin.py
```

### ğŸ”¬ Workflow

#### 1. **Configure Voxel Spacing**
Set accurate X, Y, Z voxel spacing in the "Path Tracing" tab for proper anisotropic scaling:
- Typical two-photon: 94nm Ã— 94nm Ã— 500nm
- Confocal: varies by objective and zoom

#### 2. **Trace Dendritic Paths**
- Click waypoints along dendrite structures
- Algorithm automatically finds optimal brightess paths

#### 3. **Segment Dendrites**
- Load pre-trained SAMv2 dendrite model
- Segment individual path with SAMv2

#### 4. **Detect Spines**
- Smart multi-view detection using tube data generation
- Angle-based matching between 2D and tubular views

#### 5. **Segment Spines**
- Fine-grained spine segmentation using specialized SAMv2 model
- Dendrite mask overlay to suppress background signal
- Manual point extension across frames
- Contrasting color system for visualization

### ğŸ”§ Model Training

#### Dendrite Model
```bash
cd Train-SAMv2
python train_dendrites.py --ppn 20 --pnn 10 --batch_size 32 --model_name "small"
```

#### Spine Model  
```bash
python train_spines.py --model_name "small" --batch_size 16
```

### ğŸ“ Data Format

#### Input Requirements
- **Image Format**: TIFF format
- **Dimensions**: 3D volumes (ZÃ—YÃ—X) 
- **Bit Depth**: 8-bit or 16-bit grayscale
- **Size**: Tested up to 2048Ã—2048Ã—500 voxels

#### Output Formats
- **Paths**: NumPy arrays with coordinates
- **Masks**: Binary TIFF volumes

### ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.


#### Useful VSCode Extensions

- [Remote Explorer](https://marketplace.visualstudio.com/items?itemName=ms-vscode.remote-explorer) - Open projects on remote servers.
- [Log Viewer](https://marketplace.visualstudio.com/items?itemName=berublan.vscode-log-viewer) - A log monitoring extension.
- [Black Formatter](https://marketplace.visualstudio.com/items?itemName=ms-python.black-formatter) - Python auto code formatter.
- [Markdown All in One](https://marketplace.visualstudio.com/items?itemName=yzhang.markdown-all-in-one) - Markdown preview and editing.

### ğŸ“¬  Contact

Nipun Arora - nipun.arora@fau.de

---
<div align="center">
<b>Made with â™¥ï¸ at Anki Lab ğŸ§ âœ¨</b>
</div>